INFO:root:Input args: Namespace(dname='MNIST', seeds=[0], architecture='MNIST_CNN', accountant='rdp', individualize='clipping', log_iteration=100, lr=0.6, momentum=0.5, epochs=80, n_workers=6, batch_size=512, max_physical_batch_size=128, delta=1e-05, budgets=[1.0, 2.0, 3.0], ratios=[0.34, 0.43, 0.23], max_grad_norm=0.2, noise_multiplier=3.42529, weights=None, adapt_weights_to_budgets=True, use_cuda='True', save_path='../mnist_results/clipping/MNIST/epochs_80_batch_512_lr_0.6_max_grad_norm_0.2_budgets_1.0_2.0_3.0_ratios_0.34_0.43_0.23_seeds_0', mode='mia', accuracy_log='accuracy.log', assign_budget='even', class_budgets=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], mia_ndata=50000, mia_count=0, allow_excess=False, save_model='True')
INFO:root:seed: 0,   max_iteration: 9375,   1 epoch ~= 117 iterations
INFO:root:seed: 0,   max_iteration: 7812,   1 epoch ~= 98 iterations
INFO:root:Initializing privacy parameters:   max_grad_norm=0.2,   sample_rate=0.01020408163265306,   noise_multiplier 2.4533072021484372,   individual max_grad_norms=[0.13101364146023467, 0.2354715008787346, 0.32002376751592354]
INFO:root:iteration: 0,   train accuracy: 10.2,   test accuracy: 10.08,   loss: 2.31051,   DP costs: [0.045, 0.177, 0.36],   average batch-size: 512,   best alpha: [128.17, 40.11, 22.02],   time: 1
INFO:root:iteration: 100,   train accuracy: 72.42,   test accuracy: 74.2,   loss: 1.04965,   DP costs: [0.1, 0.242, 0.449],   average batch-size: 518,   best alpha: [120.05, 38.99, 20.9],   time: 9
INFO:root:iteration: 200,   train accuracy: 82.29,   test accuracy: 83.63,   loss: 0.7322,   DP costs: [0.142, 0.301, 0.517],   average batch-size: 499,   best alpha: [89.82, 38.68, 20.66],   time: 18
