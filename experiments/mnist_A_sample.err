Input args: Namespace(dname='MNIST', seeds=[0], architecture='MNIST_CNN', accountant='rdp', individualize='sampling', log_iteration=100, lr=0.6, momentum=0.5, epochs=80, n_workers=6, batch_size=512, max_physical_batch_size=1024, delta=1e-05, budgets=[1.0, 2.0, 3.0], ratios=[0.34, 0.43, 0.23], max_grad_norm=0.2, noise_multiplier=3.42529, weights=None, adapt_weights_to_budgets=True, use_cuda='True', save_path='../mnist_results/sampling/MNIST/epochs_80_batch_512_lr_0.6_max_grad_norm_0.2_budgets_1.0_2.0_3.0_ratios_0.34_0.43_0.23_seeds_0', mode='mia', accuracy_log='accuracy.log', assign_budget='even', class_budgets=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], mia_ndata=60000, mia_count=0, allow_excess=False, save_model='True')
seed: 0,   max_iteration: 9375,   1 epoch ~= 117 iterations
seed: 0,   max_iteration: 9375,   1 epoch ~= 117 iterations
/local/scratch/manwa22/idp-sgd/experiments/../opacus/opacus/privacy_engine.py:126: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/local/scratch/manwa22/idp-sgd/experiments/../opacus/opacus/accountants/analysis/rdp.py:74: RuntimeWarning: invalid value encountered in scalar subtract
  return math.log1p(math.exp(a - b)) + b  # log1p(x) = log(x + 1)
Initializing privacy parameters:   max_grad_norm=0.2,   sample_rate=0.00847457627118644,   noise_multiplier 1.9369383544921877,   individual sample_rates=[0.004544068337371826, 0.008551026305114747, 0.012316895408081056]
/local/scratch/manwa22/miniconda3/envs/idp/lib/python3.9/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
iteration: 0,   train accuracy: 10.21,   test accuracy: 10.01,   loss: 2.31215,   DP costs: [0.172, 0.2, 0.221],   average batch-size: 508,   best alpha: [40.79, 35.95, 33.33],   time: 1
iteration: 100,   train accuracy: 70.24,   test accuracy: 71.87,   loss: 1.11198,   DP costs: [0.19, 0.25, 0.315],   average batch-size: 505,   best alpha: [39.97, 34.96, 32.05],   time: 8
iteration: 200,   train accuracy: 79.85,   test accuracy: 80.89,   loss: 0.61927,   DP costs: [0.204, 0.294, 0.401],   average batch-size: 509,   best alpha: [39.81, 34.82, 31.67],   time: 14
iteration: 300,   train accuracy: 86.37,   test accuracy: 86.68,   loss: 0.45849,   DP costs: [0.218, 0.338, 0.484],   average batch-size: 503,   best alpha: [39.65, 34.54, 30.55],   time: 20
iteration: 400,   train accuracy: 88.9,   test accuracy: 89.81,   loss: 0.33468,   DP costs: [0.231, 0.38, 0.56],   average batch-size: 510,   best alpha: [39.65, 34.4, 27.33],   time: 26
iteration: 500,   train accuracy: 91.09,   test accuracy: 91.86,   loss: 0.27758,   DP costs: [0.245, 0.423, 0.627],   average batch-size: 504,   best alpha: [39.65, 33.99, 24.95],   time: 32
iteration: 600,   train accuracy: 92.18,   test accuracy: 92.86,   loss: 0.30067,   DP costs: [0.258, 0.464, 0.688],   average batch-size: 507,   best alpha: [39.5, 32.4, 23.14],   time: 38
iteration: 700,   train accuracy: 92.94,   test accuracy: 93.56,   loss: 0.36646,   DP costs: [0.272, 0.502, 0.745],   average batch-size: 511,   best alpha: [39.5, 30.39, 21.73],   time: 43
iteration: 800,   train accuracy: 93.29,   test accuracy: 94.18,   loss: 0.18806,   DP costs: [0.285, 0.538, 0.799],   average batch-size: 508,   best alpha: [39.34, 28.74, 20.57],   time: 50
iteration: 900,   train accuracy: 93.11,   test accuracy: 94.59,   loss: 0.15968,   DP costs: [0.298, 0.572, 0.849],   average batch-size: 510,   best alpha: [39.34, 27.29, 19.62],   time: 56
iteration: 1000,   train accuracy: 94.0,   test accuracy: 94.89,   loss: 0.15783,   DP costs: [0.311, 0.604, 0.897],   average batch-size: 508,   best alpha: [39.34, 26.13, 18.8],   time: 62
iteration: 1100,   train accuracy: 95.14,   test accuracy: 95.14,   loss: 0.19189,   DP costs: [0.324, 0.635, 0.943],   average batch-size: 504,   best alpha: [39.18, 25.11, 18.08],   time: 68
iteration: 1200,   train accuracy: 95.13,   test accuracy: 95.43,   loss: 0.20888,   DP costs: [0.338, 0.664, 0.987],   average batch-size: 511,   best alpha: [39.18, 24.24, 17.39],   time: 74
iteration: 1300,   train accuracy: 95.39,   test accuracy: 95.64,   loss: 0.13622,   DP costs: [0.351, 0.693, 1.029],   average batch-size: 512,   best alpha: [39.02, 23.39, 16.85],   time: 80
iteration: 1400,   train accuracy: 95.49,   test accuracy: 95.77,   loss: 0.14052,   DP costs: [0.364, 0.72, 1.07],   average batch-size: 513,   best alpha: [39.02, 22.66, 16.34],   time: 85
iteration: 1500,   train accuracy: 95.98,   test accuracy: 96.0,   loss: 0.10535,   DP costs: [0.377, 0.747, 1.11],   average batch-size: 510,   best alpha: [38.71, 22.05, 15.9],   time: 91
iteration: 1600,   train accuracy: 95.84,   test accuracy: 96.16,   loss: 0.28662,   DP costs: [0.39, 0.772, 1.148],   average batch-size: 512,   best alpha: [38.09, 21.45, 15.48],   time: 97
iteration: 1700,   train accuracy: 96.06,   test accuracy: 96.23,   loss: 0.17645,   DP costs: [0.402, 0.797, 1.186],   average batch-size: 510,   best alpha: [37.19, 20.87, 15.07],   time: 103
iteration: 1800,   train accuracy: 96.24,   test accuracy: 96.32,   loss: 0.11621,   DP costs: [0.414, 0.822, 1.222],   average batch-size: 511,   best alpha: [36.3, 20.38, 14.72],   time: 109
iteration: 1900,   train accuracy: 96.11,   test accuracy: 96.23,   loss: 0.18557,   DP costs: [0.426, 0.845, 1.258],   average batch-size: 508,   best alpha: [35.44, 19.91, 14.39],   time: 114
iteration: 2000,   train accuracy: 96.33,   test accuracy: 96.37,   loss: 0.11497,   DP costs: [0.438, 0.869, 1.292],   average batch-size: 503,   best alpha: [34.74, 19.52, 14.06],   time: 120
iteration: 2100,   train accuracy: 96.89,   test accuracy: 96.52,   loss: 0.12732,   DP costs: [0.449, 0.891, 1.326],   average batch-size: 507,   best alpha: [33.91, 19.07, 13.79],   time: 126
iteration: 2200,   train accuracy: 95.76,   test accuracy: 96.65,   loss: 0.19401,   DP costs: [0.461, 0.914, 1.36],   average batch-size: 507,   best alpha: [33.24, 18.7, 13.53],   time: 132
iteration: 2300,   train accuracy: 96.27,   test accuracy: 96.54,   loss: 0.1427,   DP costs: [0.472, 0.935, 1.392],   average batch-size: 508,   best alpha: [32.58, 18.41, 13.28],   time: 138
iteration: 2400,   train accuracy: 96.97,   test accuracy: 96.57,   loss: 0.11936,   DP costs: [0.482, 0.957, 1.424],   average batch-size: 511,   best alpha: [32.07, 18.05, 13.03],   time: 143
iteration: 2500,   train accuracy: 96.42,   test accuracy: 96.66,   loss: 0.07628,   DP costs: [0.493, 0.978, 1.456],   average batch-size: 508,   best alpha: [31.43, 17.71, 12.83],   time: 148
iteration: 2600,   train accuracy: 96.6,   test accuracy: 96.77,   loss: 0.12657,   DP costs: [0.503, 0.998, 1.486],   average batch-size: 512,   best alpha: [30.93, 17.43, 12.64],   time: 154
iteration: 2700,   train accuracy: 96.19,   test accuracy: 96.91,   loss: 0.12914,   DP costs: [0.513, 1.018, 1.517],   average batch-size: 509,   best alpha: [30.44, 17.16, 12.4],   time: 160
iteration: 2800,   train accuracy: 96.81,   test accuracy: 96.95,   loss: 0.07941,   DP costs: [0.523, 1.038, 1.547],   average batch-size: 502,   best alpha: [29.96, 16.9, 12.26],   time: 166
iteration: 2900,   train accuracy: 97.23,   test accuracy: 96.91,   loss: 0.06358,   DP costs: [0.533, 1.058, 1.576],   average batch-size: 511,   best alpha: [29.49, 16.64, 12.08],   time: 172
iteration: 3000,   train accuracy: 96.59,   test accuracy: 96.97,   loss: 0.14568,   DP costs: [0.543, 1.077, 1.605],   average batch-size: 513,   best alpha: [29.02, 16.38, 11.89],   time: 178
iteration: 3100,   train accuracy: 96.92,   test accuracy: 97.03,   loss: 0.12436,   DP costs: [0.552, 1.096, 1.633],   average batch-size: 509,   best alpha: [28.68, 16.19, 11.72],   time: 185
iteration: 3200,   train accuracy: 96.78,   test accuracy: 97.14,   loss: 0.08136,   DP costs: [0.561, 1.115, 1.662],   average batch-size: 510,   best alpha: [28.23, 15.95, 11.58],   time: 191
iteration: 3300,   train accuracy: 96.2,   test accuracy: 97.17,   loss: 0.10813,   DP costs: [0.571, 1.133, 1.689],   average batch-size: 507,   best alpha: [27.89, 15.76, 11.41],   time: 196
iteration: 3400,   train accuracy: 96.65,   test accuracy: 97.24,   loss: 0.06547,   DP costs: [0.58, 1.151, 1.717],   average batch-size: 509,   best alpha: [27.56, 15.58, 11.28],   time: 202
iteration: 3500,   train accuracy: 97.22,   test accuracy: 97.19,   loss: 0.08974,   DP costs: [0.589, 1.169, 1.744],   average batch-size: 509,   best alpha: [27.13, 15.34, 11.16],   time: 208
iteration: 3600,   train accuracy: 96.55,   test accuracy: 97.26,   loss: 0.13136,   DP costs: [0.598, 1.187, 1.77],   average batch-size: 511,   best alpha: [26.8, 15.17, 11.03],   time: 213
iteration: 3700,   train accuracy: 97.27,   test accuracy: 97.37,   loss: 0.18258,   DP costs: [0.606, 1.205, 1.797],   average batch-size: 506,   best alpha: [26.49, 14.99, 10.91],   time: 219
iteration: 3800,   train accuracy: 97.59,   test accuracy: 97.45,   loss: 0.08302,   DP costs: [0.615, 1.222, 1.823],   average batch-size: 511,   best alpha: [26.17, 14.82, 10.79],   time: 225
iteration: 3900,   train accuracy: 97.75,   test accuracy: 97.42,   loss: 0.09825,   DP costs: [0.623, 1.239, 1.849],   average batch-size: 512,   best alpha: [25.97, 14.65, 10.67],   time: 231
iteration: 4000,   train accuracy: 97.02,   test accuracy: 97.47,   loss: 0.09344,   DP costs: [0.632, 1.256, 1.874],   average batch-size: 509,   best alpha: [25.66, 14.54, 10.55],   time: 236
iteration: 4100,   train accuracy: 97.66,   test accuracy: 97.49,   loss: 0.08723,   DP costs: [0.64, 1.273, 1.899],   average batch-size: 505,   best alpha: [25.36, 14.37, 10.43],   time: 242
iteration: 4200,   train accuracy: 96.97,   test accuracy: 97.51,   loss: 0.14077,   DP costs: [0.648, 1.289, 1.924],   average batch-size: 508,   best alpha: [25.06, 14.21, 10.35],   time: 248
iteration: 4300,   train accuracy: 97.82,   test accuracy: 97.54,   loss: 0.1203,   DP costs: [0.657, 1.306, 1.949],   average batch-size: 510,   best alpha: [24.86, 14.1, 10.24],   time: 254
iteration: 4400,   train accuracy: 96.95,   test accuracy: 97.56,   loss: 0.12469,   DP costs: [0.665, 1.322, 1.973],   average batch-size: 509,   best alpha: [24.57, 13.94, 10.12],   time: 260
iteration: 4500,   train accuracy: 96.81,   test accuracy: 97.55,   loss: 0.09651,   DP costs: [0.673, 1.338, 1.997],   average batch-size: 508,   best alpha: [24.37, 13.83, 10.05],   time: 265
iteration: 4600,   train accuracy: 97.52,   test accuracy: 97.52,   loss: 0.18272,   DP costs: [0.681, 1.354, 2.021],   average batch-size: 511,   best alpha: [24.09, 13.67, 9.97],   time: 270
iteration: 4700,   train accuracy: 97.01,   test accuracy: 97.51,   loss: 0.10796,   DP costs: [0.688, 1.37, 2.045],   average batch-size: 510,   best alpha: [23.9, 13.57, 9.86],   time: 275
iteration: 4800,   train accuracy: 97.62,   test accuracy: 97.57,   loss: 0.09879,   DP costs: [0.696, 1.385, 2.069],   average batch-size: 505,   best alpha: [23.71, 13.41, 9.79],   time: 281
iteration: 4900,   train accuracy: 97.98,   test accuracy: 97.63,   loss: 0.17336,   DP costs: [0.704, 1.401, 2.092],   average batch-size: 508,   best alpha: [23.43, 13.31, 9.68],   time: 287
iteration: 5000,   train accuracy: 97.61,   test accuracy: 97.58,   loss: 0.07499,   DP costs: [0.712, 1.416, 2.115],   average batch-size: 507,   best alpha: [23.24, 13.21, 9.61],   time: 293
iteration: 5100,   train accuracy: 96.8,   test accuracy: 97.56,   loss: 0.10981,   DP costs: [0.719, 1.431, 2.138],   average batch-size: 509,   best alpha: [23.06, 13.11, 9.54],   time: 298
iteration: 5200,   train accuracy: 97.58,   test accuracy: 97.54,   loss: 0.09353,   DP costs: [0.727, 1.446, 2.161],   average batch-size: 509,   best alpha: [22.88, 13.01, 9.47],   time: 304
iteration: 5300,   train accuracy: 97.39,   test accuracy: 97.47,   loss: 0.11963,   DP costs: [0.734, 1.461, 2.183],   average batch-size: 508,   best alpha: [22.7, 12.86, 9.4],   time: 309
iteration: 5400,   train accuracy: 97.32,   test accuracy: 97.67,   loss: 0.08864,   DP costs: [0.741, 1.476, 2.206],   average batch-size: 506,   best alpha: [22.52, 12.77, 9.33],   time: 314
iteration: 5500,   train accuracy: 98.25,   test accuracy: 97.6,   loss: 0.1076,   DP costs: [0.749, 1.491, 2.228],   average batch-size: 508,   best alpha: [22.35, 12.67, 9.26],   time: 320
iteration: 5600,   train accuracy: 97.67,   test accuracy: 97.72,   loss: 0.06161,   DP costs: [0.756, 1.505, 2.25],   average batch-size: 511,   best alpha: [22.17, 12.57, 9.2],   time: 326
iteration: 5700,   train accuracy: 98.15,   test accuracy: 97.66,   loss: 0.0594,   DP costs: [0.763, 1.52, 2.272],   average batch-size: 511,   best alpha: [22.0, 12.48, 9.13],   time: 332
iteration: 5800,   train accuracy: 96.77,   test accuracy: 97.68,   loss: 0.05996,   DP costs: [0.77, 1.534, 2.293],   average batch-size: 507,   best alpha: [21.82, 12.38, 9.06],   time: 338
iteration: 5900,   train accuracy: 98.45,   test accuracy: 97.81,   loss: 0.13955,   DP costs: [0.777, 1.548, 2.315],   average batch-size: 506,   best alpha: [21.65, 12.29, 9.0],   time: 344
iteration: 6000,   train accuracy: 97.43,   test accuracy: 97.79,   loss: 0.12424,   DP costs: [0.784, 1.562, 2.336],   average batch-size: 509,   best alpha: [21.48, 12.24, 8.93],   time: 349
iteration: 6100,   train accuracy: 97.14,   test accuracy: 97.83,   loss: 0.10806,   DP costs: [0.791, 1.576, 2.357],   average batch-size: 504,   best alpha: [21.31, 12.15, 8.87],   time: 355
iteration: 6200,   train accuracy: 97.78,   test accuracy: 97.78,   loss: 0.06725,   DP costs: [0.798, 1.59, 2.379],   average batch-size: 505,   best alpha: [21.15, 12.06, 8.8],   time: 361
iteration: 6300,   train accuracy: 97.04,   test accuracy: 97.79,   loss: 0.08402,   DP costs: [0.805, 1.604, 2.399],   average batch-size: 507,   best alpha: [20.98, 11.97, 8.74],   time: 367
iteration: 6400,   train accuracy: 98.13,   test accuracy: 97.83,   loss: 0.08189,   DP costs: [0.812, 1.618, 2.42],   average batch-size: 505,   best alpha: [20.9, 11.88, 8.7],   time: 372
iteration: 6500,   train accuracy: 97.68,   test accuracy: 97.87,   loss: 0.07723,   DP costs: [0.818, 1.631, 2.441],   average batch-size: 510,   best alpha: [20.74, 11.83, 8.64],   time: 378
iteration: 6600,   train accuracy: 97.69,   test accuracy: 97.9,   loss: 0.06034,   DP costs: [0.825, 1.645, 2.461],   average batch-size: 502,   best alpha: [20.57, 11.75, 8.58],   time: 383
iteration: 6700,   train accuracy: 97.89,   test accuracy: 97.87,   loss: 0.09496,   DP costs: [0.832, 1.658, 2.482],   average batch-size: 507,   best alpha: [20.49, 11.66, 8.52],   time: 389
iteration: 6800,   train accuracy: 97.87,   test accuracy: 97.88,   loss: 0.05217,   DP costs: [0.838, 1.672, 2.502],   average batch-size: 510,   best alpha: [20.33, 11.61, 8.49],   time: 395
iteration: 6900,   train accuracy: 97.19,   test accuracy: 97.91,   loss: 0.07294,   DP costs: [0.845, 1.685, 2.522],   average batch-size: 506,   best alpha: [20.18, 11.53, 8.42],   time: 400
iteration: 7000,   train accuracy: 97.77,   test accuracy: 97.9,   loss: 0.13954,   DP costs: [0.852, 1.698, 2.542],   average batch-size: 511,   best alpha: [20.1, 11.44, 8.39],   time: 406
iteration: 7100,   train accuracy: 98.32,   test accuracy: 97.94,   loss: 0.09703,   DP costs: [0.858, 1.711, 2.562],   average batch-size: 507,   best alpha: [19.94, 11.4, 8.33],   time: 412
iteration: 7200,   train accuracy: 98.12,   test accuracy: 97.94,   loss: 0.16498,   DP costs: [0.864, 1.724, 2.582],   average batch-size: 506,   best alpha: [19.86, 11.31, 8.27],   time: 418
iteration: 7300,   train accuracy: 98.13,   test accuracy: 97.92,   loss: 0.09336,   DP costs: [0.871, 1.737, 2.601],   average batch-size: 502,   best alpha: [19.71, 11.27, 8.24],   time: 423
iteration: 7400,   train accuracy: 97.92,   test accuracy: 97.92,   loss: 0.11117,   DP costs: [0.877, 1.75, 2.621],   average batch-size: 510,   best alpha: [19.55, 11.19, 8.18],   time: 429
iteration: 7500,   train accuracy: 97.57,   test accuracy: 97.93,   loss: 0.12714,   DP costs: [0.884, 1.763, 2.64],   average batch-size: 506,   best alpha: [19.48, 11.14, 8.15],   time: 434
iteration: 7600,   train accuracy: 97.91,   test accuracy: 97.98,   loss: 0.0928,   DP costs: [0.89, 1.776, 2.66],   average batch-size: 509,   best alpha: [19.32, 11.06, 8.09],   time: 440
iteration: 7700,   train accuracy: 97.85,   test accuracy: 97.97,   loss: 0.05937,   DP costs: [0.896, 1.788, 2.679],   average batch-size: 509,   best alpha: [19.25, 11.02, 8.07],   time: 445
iteration: 7800,   train accuracy: 98.17,   test accuracy: 97.99,   loss: 0.07531,   DP costs: [0.902, 1.801, 2.698],   average batch-size: 509,   best alpha: [19.17, 10.94, 8.01],   time: 451
iteration: 7900,   train accuracy: 98.08,   test accuracy: 98.01,   loss: 0.08077,   DP costs: [0.909, 1.813, 2.717],   average batch-size: 506,   best alpha: [19.03, 10.9, 7.98],   time: 456
iteration: 8000,   train accuracy: 97.95,   test accuracy: 97.96,   loss: 0.11402,   DP costs: [0.915, 1.826, 2.736],   average batch-size: 508,   best alpha: [18.95, 10.81, 7.95],   time: 463
iteration: 8100,   train accuracy: 98.23,   test accuracy: 97.96,   loss: 0.08668,   DP costs: [0.921, 1.838, 2.755],   average batch-size: 507,   best alpha: [18.8, 10.77, 7.89],   time: 468
iteration: 8200,   train accuracy: 97.61,   test accuracy: 97.91,   loss: 0.09076,   DP costs: [0.927, 1.85, 2.773],   average batch-size: 505,   best alpha: [18.73, 10.73, 7.86],   time: 474
iteration: 8300,   train accuracy: 98.04,   test accuracy: 97.97,   loss: 0.0862,   DP costs: [0.933, 1.863, 2.792],   average batch-size: 507,   best alpha: [18.66, 10.65, 7.81],   time: 479
iteration: 8400,   train accuracy: 97.93,   test accuracy: 98.01,   loss: 0.06998,   DP costs: [0.939, 1.875, 2.811],   average batch-size: 508,   best alpha: [18.51, 10.61, 7.78],   time: 486
iteration: 8500,   train accuracy: 97.61,   test accuracy: 97.97,   loss: 0.09696,   DP costs: [0.945, 1.887, 2.829],   average batch-size: 505,   best alpha: [18.44, 10.57, 7.75],   time: 492
iteration: 8600,   train accuracy: 97.95,   test accuracy: 97.93,   loss: 0.06113,   DP costs: [0.951, 1.899, 2.847],   average batch-size: 508,   best alpha: [18.37, 10.5, 7.7],   time: 497
iteration: 8700,   train accuracy: 97.76,   test accuracy: 97.94,   loss: 0.09921,   DP costs: [0.957, 1.911, 2.866],   average batch-size: 506,   best alpha: [18.23, 10.46, 7.67],   time: 502
iteration: 8800,   train accuracy: 98.61,   test accuracy: 97.91,   loss: 0.08258,   DP costs: [0.963, 1.923, 2.884],   average batch-size: 508,   best alpha: [18.15, 10.42, 7.64],   time: 508
iteration: 8900,   train accuracy: 98.0,   test accuracy: 97.91,   loss: 0.07285,   DP costs: [0.969, 1.935, 2.902],   average batch-size: 510,   best alpha: [18.08, 10.34, 7.61],   time: 514
iteration: 9000,   train accuracy: 98.06,   test accuracy: 97.83,   loss: 0.07887,   DP costs: [0.974, 1.947, 2.92],   average batch-size: 509,   best alpha: [18.01, 10.3, 7.56],   time: 520
iteration: 9100,   train accuracy: 97.35,   test accuracy: 97.8,   loss: 0.02583,   DP costs: [0.98, 1.958, 2.938],   average batch-size: 510,   best alpha: [17.87, 10.26, 7.53],   time: 525
iteration: 9200,   train accuracy: 98.16,   test accuracy: 97.86,   loss: 0.06666,   DP costs: [0.986, 1.97, 2.955],   average batch-size: 507,   best alpha: [17.8, 10.23, 7.51],   time: 531
iteration: 9300,   train accuracy: 98.4,   test accuracy: 97.88,   loss: 0.1142,   DP costs: [0.992, 1.982, 2.973],   average batch-size: 512,   best alpha: [17.74, 10.15, 7.48],   time: 537
iteration: 9374,   train accuracy: 98.27,   test accuracy: 97.96,   loss: 0.05953,   DP costs: [0.996, 1.99, 2.986],   average batch-size: 507,   best alpha: [17.67, 10.15, 7.45],   time: 542
Terminate: The maximum of iterations is reached!
