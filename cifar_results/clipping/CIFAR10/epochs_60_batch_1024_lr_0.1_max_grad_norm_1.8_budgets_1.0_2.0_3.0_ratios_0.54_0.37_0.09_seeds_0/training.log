INFO:root:Input args: Namespace(dname='CIFAR10', seeds=[0], architecture='CIFAR10_CNN', accountant='rdp', individualize='clipping', log_iteration=100, lr=0.1, momentum=0.5, epochs=60, n_workers=6, batch_size=1024, max_physical_batch_size=128, delta=1e-05, budgets=[1.0, 2.0, 3.0], ratios=[0.54, 0.37, 0.09], max_grad_norm=1.8, noise_multiplier=3.17792, weights=None, adapt_weights_to_budgets=True, use_cuda='True', save_path='../cifar_results/clipping/CIFAR10/epochs_60_batch_1024_lr_0.1_max_grad_norm_1.8_budgets_1.0_2.0_3.0_ratios_0.54_0.37_0.09_seeds_0', mode='mia', accuracy_log='accuracy.log', assign_budget='even', class_budgets=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], mia_ndata=50000, mia_count=0, allow_excess=False, save_model='True')
INFO:root:seed: 0,   max_iteration: 2930,   1 epoch ~= 49 iterations
INFO:root:seed: 0,   max_iteration: 2930,   1 epoch ~= 49 iterations
INFO:root:Initializing privacy parameters:   max_grad_norm=1.8,   sample_rate=0.02040816326530612,   noise_multiplier 2.9691111328125,   individual max_grad_norms=[1.169997998931053, 2.125307044660194, 2.9285167304347826]
INFO:root:iteration: 0,   train accuracy: 10.23,   test accuracy: 10.24,   loss: 2.30016,   DP costs: [0.036, 0.141, 0.295],   average batch-size: 942,   best alpha: [161.29, 49.13, 26.2],   time: 1
INFO:root:iteration: 100,   train accuracy: 28.16,   test accuracy: 28.79,   loss: 2.03829,   DP costs: [0.167, 0.344, 0.538],   average batch-size: 1030,   best alpha: [77.58, 40.32, 24.38],   time: 31
INFO:root:iteration: 200,   train accuracy: 33.52,   test accuracy: 34.59,   loss: 1.89793,   DP costs: [0.24, 0.486, 0.741],   average batch-size: 1022,   best alpha: [57.9, 30.83, 20.91],   time: 61
INFO:root:iteration: 300,   train accuracy: 38.39,   test accuracy: 38.73,   loss: 1.94464,   DP costs: [0.296, 0.598, 0.906],   average batch-size: 1014,   best alpha: [48.46, 26.08, 17.95],   time: 89
INFO:root:iteration: 400,   train accuracy: 41.39,   test accuracy: 42.05,   loss: 1.83327,   DP costs: [0.345, 0.693, 1.047],   average batch-size: 1023,   best alpha: [42.77, 23.16, 16.1],   time: 118
INFO:root:iteration: 500,   train accuracy: 43.86,   test accuracy: 44.1,   loss: 1.63919,   DP costs: [0.388, 0.778, 1.173],   average batch-size: 1018,   best alpha: [38.68, 21.16, 14.79],   time: 146
INFO:root:iteration: 600,   train accuracy: 44.73,   test accuracy: 45.09,   loss: 1.54506,   DP costs: [0.427, 0.856, 1.288],   average batch-size: 1026,   best alpha: [35.69, 19.56, 13.75],   time: 175
INFO:root:iteration: 700,   train accuracy: 46.13,   test accuracy: 46.12,   loss: 1.38753,   DP costs: [0.464, 0.928, 1.395],   average batch-size: 1010,   best alpha: [33.34, 18.38, 12.94],   time: 203
INFO:root:iteration: 800,   train accuracy: 47.02,   test accuracy: 47.34,   loss: 1.47876,   DP costs: [0.498, 0.996, 1.495],   average batch-size: 1016,   best alpha: [31.4, 17.33, 12.27],   time: 231
INFO:root:iteration: 900,   train accuracy: 47.38,   test accuracy: 46.79,   loss: 1.58175,   DP costs: [0.53, 1.06, 1.591],   average batch-size: 1025,   best alpha: [29.82, 16.55, 11.72],   time: 259
INFO:root:iteration: 1000,   train accuracy: 48.74,   test accuracy: 48.53,   loss: 1.53004,   DP costs: [0.561, 1.12, 1.681],   average batch-size: 1021,   best alpha: [28.54, 15.8, 11.25],   time: 287
INFO:root:iteration: 1100,   train accuracy: 49.46,   test accuracy: 49.05,   loss: 1.67716,   DP costs: [0.59, 1.179, 1.768],   average batch-size: 1010,   best alpha: [27.32, 15.2, 10.83],   time: 315
INFO:root:iteration: 1200,   train accuracy: 50.46,   test accuracy: 50.6,   loss: 1.5447,   DP costs: [0.618, 1.234, 1.851],   average batch-size: 1029,   best alpha: [26.25, 14.62, 10.48],   time: 343
INFO:root:iteration: 1300,   train accuracy: 51.62,   test accuracy: 51.41,   loss: 1.35712,   DP costs: [0.645, 1.288, 1.931],   average batch-size: 1014,   best alpha: [25.33, 14.18, 10.13],   time: 371
INFO:root:iteration: 1400,   train accuracy: 52.16,   test accuracy: 52.53,   loss: 1.28993,   DP costs: [0.671, 1.34, 2.009],   average batch-size: 1012,   best alpha: [24.54, 13.7, 9.83],   time: 398
INFO:root:iteration: 1500,   train accuracy: 52.62,   test accuracy: 52.9,   loss: 1.30581,   DP costs: [0.696, 1.39, 2.084],   average batch-size: 1025,   best alpha: [23.78, 13.34, 9.58],   time: 427
INFO:root:iteration: 1600,   train accuracy: 54.52,   test accuracy: 53.99,   loss: 1.48303,   DP costs: [0.721, 1.439, 2.157],   average batch-size: 1004,   best alpha: [23.13, 12.99, 9.34],   time: 454
INFO:root:iteration: 1700,   train accuracy: 55.3,   test accuracy: 54.65,   loss: 1.28237,   DP costs: [0.745, 1.487, 2.229],   average batch-size: 1024,   best alpha: [22.5, 12.65, 9.1],   time: 482
INFO:root:iteration: 1800,   train accuracy: 55.22,   test accuracy: 55.0,   loss: 1.26634,   DP costs: [0.768, 1.533, 2.298],   average batch-size: 1043,   best alpha: [21.98, 12.36, 8.9],   time: 511
INFO:root:iteration: 1900,   train accuracy: 55.89,   test accuracy: 55.92,   loss: 1.51698,   DP costs: [0.79, 1.578, 2.366],   average batch-size: 1028,   best alpha: [21.46, 12.09, 8.71],   time: 539
INFO:root:iteration: 2000,   train accuracy: 56.08,   test accuracy: 56.17,   loss: 1.35404,   DP costs: [0.813, 1.623, 2.432],   average batch-size: 1023,   best alpha: [20.96, 11.82, 8.55],   time: 567
INFO:root:iteration: 2100,   train accuracy: 56.08,   test accuracy: 56.83,   loss: 1.67006,   DP costs: [0.834, 1.666, 2.497],   average batch-size: 1030,   best alpha: [20.48, 11.59, 8.37],   time: 595
INFO:root:iteration: 2200,   train accuracy: 57.31,   test accuracy: 57.0,   loss: 1.30406,   DP costs: [0.855, 1.708, 2.561],   average batch-size: 994,   best alpha: [20.08, 11.38, 8.22],   time: 623
INFO:root:iteration: 2300,   train accuracy: 57.11,   test accuracy: 56.71,   loss: 1.24892,   DP costs: [0.876, 1.75, 2.623],   average batch-size: 1025,   best alpha: [19.69, 11.17, 8.07],   time: 651
INFO:root:iteration: 2400,   train accuracy: 57.73,   test accuracy: 56.97,   loss: 1.38185,   DP costs: [0.896, 1.79, 2.685],   average batch-size: 1025,   best alpha: [19.31, 10.96, 7.96],   time: 680
INFO:root:iteration: 2500,   train accuracy: 57.59,   test accuracy: 57.48,   loss: 1.23181,   DP costs: [0.916, 1.83, 2.745],   average batch-size: 1009,   best alpha: [19.01, 10.76, 7.81],   time: 707
INFO:root:iteration: 2600,   train accuracy: 58.4,   test accuracy: 57.42,   loss: 1.24531,   DP costs: [0.936, 1.87, 2.804],   average batch-size: 1018,   best alpha: [18.64, 10.6, 7.7],   time: 735
INFO:root:iteration: 2700,   train accuracy: 59.18,   test accuracy: 57.93,   loss: 1.10313,   DP costs: [0.955, 1.908, 2.862],   average batch-size: 1015,   best alpha: [18.35, 10.44, 7.59],   time: 764
INFO:root:iteration: 2800,   train accuracy: 58.83,   test accuracy: 58.12,   loss: 1.35605,   DP costs: [0.974, 1.947, 2.92],   average batch-size: 1008,   best alpha: [18.07, 10.28, 7.48],   time: 791
INFO:root:iteration: 2900,   train accuracy: 59.0,   test accuracy: 58.46,   loss: 1.26575,   DP costs: [0.992, 1.984, 2.976],   average batch-size: 1006,   best alpha: [17.79, 10.13, 7.38],   time: 818
INFO:root:iteration: 2929,   train accuracy: 59.46,   test accuracy: 58.51,   loss: 1.28298,   DP costs: [0.998, 1.995, 2.992],   average batch-size: 1024,   best alpha: [17.72, 10.1, 7.35],   time: 829
INFO:root:Terminate: The maximum of iterations is reached!
