INFO:root:Input args: Namespace(dname='SVHN', seeds=[0], architecture='CIFAR10_CNN', accountant='rdp', individualize=None, log_iteration=100, lr=0.2, momentum=0.5, epochs=30, n_workers=6, batch_size=1024, max_physical_batch_size=1024, delta=1e-05, budgets=[1.0, 2.0, 3.0], ratios=[0.34, 0.43, 0.23], max_grad_norm=0.9, noise_multiplier=2.74658, weights=None, adapt_weights_to_budgets=True, use_cuda='True', save_path='../svhn_results/standard/SVHN/epochs_30_batch_1024_lr_0.2_max_grad_norm_0.9_budgets_1.0_2.0_3.0_ratios_0.34_0.43_0.23_seeds_0', mode='mia', accuracy_log='accuracy.log', assign_budget='even', class_budgets=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], mia_ndata=73257, mia_count=0, allow_excess=False, save_model='True')
INFO:root:seed: 0,   max_iteration: 2146,   1 epoch ~= 72 iterations
INFO:root:seed: 0,   max_iteration: 2146,   1 epoch ~= 72 iterations
INFO:root:Initializing privacy parameters:   max_grad_norm=0.9,   sample_rate=0.013888888888888888,   noise_multiplier 2.74658203125,   no individual parameters
INFO:root:iteration: 0,   train accuracy: 11.14,   test accuracy: 10.08,   loss: 2.30076,   DP costs: 0.102,   average batch-size: 923,   best alpha: 64.51,   time: 1
INFO:root:iteration: 100,   train accuracy: 18.93,   test accuracy: 19.59,   loss: 2.21939,   DP costs: 0.203,   average batch-size: 1035,   best alpha: 62.7,   time: 11
INFO:root:iteration: 200,   train accuracy: 18.87,   test accuracy: 19.59,   loss: 2.23508,   DP costs: 0.288,   average batch-size: 928,   best alpha: 48.39,   time: 21
INFO:root:iteration: 300,   train accuracy: 19.08,   test accuracy: 19.59,   loss: 2.2296,   DP costs: 0.354,   average batch-size: 1132,   best alpha: 40.85,   time: 32
INFO:root:iteration: 400,   train accuracy: 18.93,   test accuracy: 19.59,   loss: 2.25243,   DP costs: 0.411,   average batch-size: 1003,   best alpha: 36.22,   time: 43
INFO:root:iteration: 500,   train accuracy: 18.88,   test accuracy: 19.59,   loss: 2.21645,   DP costs: 0.461,   average batch-size: 981,   best alpha: 32.9,   time: 52
INFO:root:iteration: 600,   train accuracy: 18.86,   test accuracy: 19.59,   loss: 2.24574,   DP costs: 0.507,   average batch-size: 1031,   best alpha: 30.49,   time: 63
INFO:root:iteration: 700,   train accuracy: 18.85,   test accuracy: 19.59,   loss: 2.24635,   DP costs: 0.55,   average batch-size: 1019,   best alpha: 28.5,   time: 73
INFO:root:iteration: 800,   train accuracy: 18.65,   test accuracy: 19.59,   loss: 2.24048,   DP costs: 0.59,   average batch-size: 1030,   best alpha: 26.95,   time: 83
INFO:root:iteration: 900,   train accuracy: 18.94,   test accuracy: 19.59,   loss: 2.24652,   DP costs: 0.628,   average batch-size: 986,   best alpha: 25.6,   time: 93
INFO:root:iteration: 1000,   train accuracy: 18.88,   test accuracy: 19.59,   loss: 2.2414,   DP costs: 0.664,   average batch-size: 969,   best alpha: 24.51,   time: 102
INFO:root:iteration: 1100,   train accuracy: 18.81,   test accuracy: 19.57,   loss: 2.25989,   DP costs: 0.698,   average batch-size: 981,   best alpha: 23.47,   time: 110
INFO:root:iteration: 1200,   train accuracy: 18.94,   test accuracy: 19.61,   loss: 2.23698,   DP costs: 0.731,   average batch-size: 1011,   best alpha: 22.65,   time: 119
INFO:root:iteration: 1300,   train accuracy: 18.88,   test accuracy: 19.54,   loss: 2.23572,   DP costs: 0.763,   average batch-size: 1019,   best alpha: 21.86,   time: 128
INFO:root:iteration: 1400,   train accuracy: 18.87,   test accuracy: 19.6,   loss: 2.2279,   DP costs: 0.793,   average batch-size: 988,   best alpha: 21.18,   time: 138
INFO:root:iteration: 1500,   train accuracy: 18.96,   test accuracy: 19.66,   loss: 2.23799,   DP costs: 0.823,   average batch-size: 980,   best alpha: 20.53,   time: 148
INFO:root:iteration: 1600,   train accuracy: 18.89,   test accuracy: 19.66,   loss: 2.25222,   DP costs: 0.852,   average batch-size: 1060,   best alpha: 19.97,   time: 158
INFO:root:iteration: 1700,   train accuracy: 18.79,   test accuracy: 19.65,   loss: 2.20993,   DP costs: 0.88,   average batch-size: 1006,   best alpha: 19.43,   time: 168
INFO:root:iteration: 1800,   train accuracy: 18.74,   test accuracy: 19.7,   loss: 2.26597,   DP costs: 0.907,   average batch-size: 1001,   best alpha: 18.98,   time: 178
INFO:root:iteration: 1900,   train accuracy: 18.9,   test accuracy: 20.25,   loss: 2.2397,   DP costs: 0.933,   average batch-size: 1007,   best alpha: 18.54,   time: 189
INFO:root:iteration: 2000,   train accuracy: 18.21,   test accuracy: 20.77,   loss: 2.23778,   DP costs: 0.959,   average batch-size: 1037,   best alpha: 18.11,   time: 199
INFO:root:iteration: 2100,   train accuracy: 18.95,   test accuracy: 19.68,   loss: 2.22639,   DP costs: 0.985,   average batch-size: 1076,   best alpha: 17.76,   time: 209
INFO:root:iteration: 2145,   train accuracy: 19.19,   test accuracy: 19.53,   loss: 2.23585,   DP costs: 0.996,   average batch-size: 1106,   best alpha: 17.63,   time: 217
INFO:root:Terminate: The maximum of iterations is reached!
