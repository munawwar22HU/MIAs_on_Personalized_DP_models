INFO:root:Input args: Namespace(dname='MNIST', seeds=[0], architecture='MNIST_CNN', accountant='rdp', individualize='clipping', log_iteration=100, lr=0.6, momentum=0.5, epochs=80, n_workers=6, batch_size=1024, max_physical_batch_size=128, delta=1e-05, budgets=[1.0, 2.0, 3.0], ratios=[0.34, 0.43, 0.23], max_grad_norm=0.2, noise_multiplier=1.396484375, weights=None, adapt_weights_to_budgets=True, use_cuda='True', save_path='../mnist1_results/clipping/MNIST/epochs_80_batch_1024_lr_0.6_max_grad_norm_0.2_budgets_1.0_2.0_3.0_ratios_0.34_0.43_0.23_seeds_0', mode='mia', accuracy_log='accuracy.log', assign_budget='even', class_budgets=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], mia_ndata=25000, mia_count=0, allow_excess=False, save_model='True')
INFO:root:seed: 0,   max_iteration: 4688,   1 epoch ~= 59 iterations
INFO:root:seed: 0,   max_iteration: 1953,   1 epoch ~= 24 iterations
INFO:root:Initializing privacy parameters:   max_grad_norm=0.2,   sample_rate=0.04,   noise_multiplier 4.687651171875,   individual max_grad_norms=[0.1281750280373832, 0.23733769097651425, 0.3345055609756098]
INFO:root:iteration: 0,   train accuracy: 9.72,   test accuracy: 9.9,   loss: 2.31438,   DP costs: [0.021, 0.068, 0.144],   average batch-size: 1030,   best alpha: [338.78, 98.86, 49.86],   time: 1
INFO:root:iteration: 100,   train accuracy: 72.16,   test accuracy: 74.42,   loss: 0.99156,   DP costs: [0.203, 0.41, 0.62],   average batch-size: 1004,   best alpha: [66.92, 35.91, 24.75],   time: 20
INFO:root:iteration: 200,   train accuracy: 82.34,   test accuracy: 83.06,   loss: 0.64756,   DP costs: [0.292, 0.586, 0.88],   average batch-size: 997,   best alpha: [49.38, 26.94, 18.8],   time: 38
